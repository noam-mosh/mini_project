{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theoretical Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This is the theoretical part of the final project. It includes theoretical questions from various topics covered in the course.\n",
    "* There are 7 questions among which you need to choose 6, according to the following key:\n",
    "    + Question 1 is **mandatory**.\n",
    "    + Choose **one question** from questions 2-3.\n",
    "    + Question 4 is **mandatory**.\n",
    "    + Questions 5-6 are **mandatory**.\n",
    "    + Question 7 is **mandatory**.\n",
    "* Question 1 is worth 15 points, whereas the other questions worth 7 points.\n",
    "* All in all, the maximal grade for this parts is 15+7*5=50 points.\n",
    "* **You should answer the questions on your own. We will check for plagiarism.**\n",
    "* If you need to add external images (such as graphs) to this notebook, please put them inside the 'imgs' folder. DO NOT put a reference to an external link.\n",
    "* Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: General understanding of the course material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  Relate the number of parameters in a neural network to the over-fitting phenomenon (*).\n",
    "    Relate this to the design of convolutional neural networks, and explain why CNNs are a plausible choice for an hypothesis class for visual classification tasks.\n",
    "\n",
    "    (*) In the context of classical under-fitting/over-fitting in machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The number of parameters in a neural network is closely related to the overfitting phenomenon in machine learning. Overfitting occurs when a model learns to perform very well on the training data but fails to generalize to new, unseen data. In other words, the model becomes too specialized to the training data and captures noise or irrelevant patterns, rather than the underlying true patterns that would generalize well to new examples.\n",
    "\n",
    "The relationship between the number of parameters and overfitting can be understood as follows:\n",
    "\n",
    "1. **Too Few Parameters (Underfitting):** When a neural network has too few parameters relative to the complexity of the data it's trying to learn, it might not have enough capacity to capture the underlying patterns. As a result, the model might underfit the training data, leading to poor performance both on the training set and on unseen data.\n",
    "\n",
    "2. **Too Many Parameters (Overfitting):** On the other hand, if a neural network has too many parameters, it can potentially memorize the training data, including noise and outliers. This can lead to excellent performance on the training set but poor generalization to new data. The model becomes overly complex and fits the noise present in the training data, resulting in high variance and poor performance on unseen examples.\n",
    "\n",
    "Convolutional Neural Networks (CNNs) are a plausible choice for an hypothesis class (model architecture) for visual classification tasks due to several reasons:\n",
    "\n",
    "1. **Local Receptive Fields:** CNNs are designed to mimic the human visual system's ability to recognize patterns hierarchically. They use small, local receptive fields to scan the input data, which is well-suited for capturing spatial hierarchies and local patterns in images.\n",
    "\n",
    "2. **Parameter Sharing:** CNNs employ weight sharing across different spatial locations in an image. This significantly reduces the number of parameters compared to fully connected networks, making CNNs more resistant to overfitting. This parameter sharing enforces translation invariance, allowing the network to learn features that are useful regardless of their location in the image.\n",
    "\n",
    "3. **Hierarchical Feature Learning:** CNNs are designed with multiple layers, each learning increasingly complex and abstract features. This hierarchical feature learning enables the network to capture different levels of information, from simple edges and textures to more complex object parts and even higher-level concepts.\n",
    "\n",
    "4. **Pooling and Regularization:** CNNs often use pooling layers to downsample the spatial dimensions of feature maps, which helps in reducing the sensitivity of the network to small spatial shifts and noise. Furthermore, techniques like dropout can be applied to CNNs to prevent overfitting by randomly deactivating neurons during training.\n",
    "\n",
    "5. **Data Augmentation:** CNNs can handle variations in scale, rotation, and position due to their local receptive fields. This inherent robustness, combined with data augmentation techniques, helps reduce overfitting by exposing the network to a diverse range of training examples.\n",
    "\n",
    "In summary, CNNs strike a balance between capturing relevant features from visual data and controlling the model's complexity to prevent overfitting. Their design principles, such as local receptive fields, parameter sharing, hierarchical feature learning, and built-in regularization, make them a strong candidate for visual classification tasks."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Consider the linear classifier model with hand-crafted features: \n",
    "    $$f_{w,b}(x) = w^T \\psi(x) + b$$\n",
    "    where $x \\in \\mathbb{R}^2$, $\\psi$ is a non-learnable feature extractor and assume that the classification is done by $sign(f_{w,b}(x))$. Let $\\psi$ be the following feature extractor $\\psi(x)=x^TQx$ where $Q \\in \\mathbb{R}^{2 \\times 2}$ is a non-learnable positive definite matrix. Describe a distribution of the data which the model is able to approximate, but the simple linear model fails to approximate (hint: first, try to describe the decision boundary of the above classifier)."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The given linear classifier model with hand-crafted features is defined as:\n",
    "\n",
    "\\[ f(x) = w^T \\cdot \\psi(x) + b \\]\n",
    "\n",
    "where \\( x \\in \\mathbb{R}^2 \\), \\( \\psi \\) is a non-learnable feature extractor, and the classification is done using the sign function of \\( f(x) \\).\n",
    "\n",
    "The feature extractor \\( \\psi(x) = x^T Q x \\), where \\( Q \\in \\mathbb{R}^{2 \\times 2} \\) is a non-learnable positive definite matrix.\n",
    "\n",
    "To describe the decision boundary of the classifier, we need to find the points where \\( f(x) = 0 \\), which gives us:\n",
    "\n",
    "\\[ w^T \\cdot \\psi(x) + b = 0 \\]\n",
    "\\[ w^T \\cdot (x^T Q x) + b = 0 \\]\n",
    "\\[ x^T (Q^T w) x + b = 0 \\]\n",
    "\n",
    "This equation represents a quadratic decision boundary in the \\( x \\)-space.\n",
    "\n",
    "Now, let's consider a distribution of data that the given model is able to approximate, but a simple linear model (without the non-learnable feature extractor) fails to approximate. \n",
    "\n",
    "Imagine a scenario where the data is distributed in a way that is not linearly separable in the original \\( x \\)-space, but it is linearly separable in the transformed feature space after applying the feature extractor \\( \\psi \\). In other words, the positive definite matrix \\( Q \\) transforms the data into a space where a linear decision boundary is sufficient to separate the classes.\n",
    "\n",
    "For instance, consider a distribution of data where one class forms a ring or ellipse-like shape, and the other class is contained within that ring or ellipse. The simple linear model would struggle to find a linear boundary to separate these classes in the original \\( x \\)-space. However, the feature extractor \\( \\psi \\) defined by \\( Q \\) could map the data into a higher-dimensional space where a linear decision boundary (or a plane) can easily separate the classes.\n",
    "\n",
    "In this scenario, the linear classifier model with the hand-crafted features can approximate the distribution effectively due to the transformation induced by the positive definite matrix \\( Q \\), while a simple linear model would fail to capture the underlying patterns. This demonstrates the advantage of using a non-linear feature extractor in cases where the data distribution is inherently non-linear in the original input space."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Assume that we would like to train a Neural Network for classifying images into $C$ classes. Assume that the architecture can be stored in the memory as a computational graph with $N$ nodes where the output is the logits (namely, before applying softmax) for the current batch ($f_w: B \\times Ch \\times H \\times W \\rightarrow B \\times C$). Assume that the computational graph operates on *tensor* values.\n",
    "    * Implement the CE loss assuming that the labels $y$ are hard labels given in a LongTensor of shape $B \\times 1$. **Use Torch's log_softmax and gather functions** and implement with less as possible operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import log_softmax\n",
    "from torch import gather\n",
    "# Input:  model, x, y. \n",
    "# Output: the loss on the current batch.\n",
    "logits = model(x)\n",
    "...\n",
    "loss = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using the model's function as a black box, draw the computational graph (treating both log_softmax and gather as an atomic operations). How many nodes are there in the computational graph?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, instead of using hard labels, assume that the labels are representing some probability distribution over the $C$ classes. How would the gradient computation be affected? analyze the growth in the computational graph, memory and computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Apply the same analysis in the case that we would like to double the batch size. How should we change the learning rate of the optimizer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Optimization & Automatic Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: resolving gradient conflicts in multi-task learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that you want to train a model to perform two tasks: task 1 and task 2. \n",
    "For each such task $i$ you have an already implemented function *loss\\_i = forward_and_compute_loss_i(model,inputs)* such that given the model and the inputs it computes the loss w.r.t task $i$ (assume that the computational graph is properly constructed). We would like to train our model using SGD to succeed in both tasks as follows: in each training iteration (batch) -\n",
    "* Let $g_i$ be the gradient w.r.t the $i$-th task.\n",
    "* If $g_1 \\cdot g_2 < 0$:\n",
    "    + Pick a task $i$ at random.\n",
    "    + Apply GD w.r.t only that task.\n",
    "* Otherwise:\n",
    "    + Apply GD w.r.t both tasks (namely $\\mathcal{L}_1 + \\mathcal{L}_2$).\n",
    "\n",
    "Note that in the above formulation the gradient is a thought of as a concatination of all the gradient w.r.t all the models parameters, and $g_1 \\cdot g_2$ stands for a dot product.\n",
    "\n",
    "What parts should be modified to implement the above? Is it the optimizer, the training loop or both? Implement the above algorithm in a code cell/s below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: manual automatic differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following two-input two-output function:\n",
    "$$ f(x,y) = (x^2\\sin(xy+\\frac{\\pi}{2}), x^2\\ln(1+xy)) $$\n",
    "* Draw a computational graph for the above function. Assume that the unary atomic units are squaring, taking square root, $\\exp,\\ln$, basic trigonometric functions and the binary atomic units are addition and multiplication. You would have to use constant nodes.\n",
    "* Calculate manually the forward pass.\n",
    "* Calculate manually the derivative of all outputs w.r.t all inputs using a forward mode AD.\n",
    "* Calculate manually the derivative of all outputs w.r.t all inputs using a backward mode AD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Sequential Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: RNNs vs Transformers in the real life"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each one of the following scenarios decide whether to use RNN based model or a transformer based model. Justify your choice.\n",
    "1. You are running a start-up in the area of automatic summarization of academic papers. The inference of the model is done on the server side, and it is very important for it to be fast.\n",
    "2. You need to design a mobile application that gathers small amount of data from few apps in every second and then uses a NN to possibly generate an alert given the information in the current second and the information from the past minute.\n",
    "3. You have a prediction task over fixed length sequences on which you know the following properties:\n",
    "    + In each sequence there are only few tokens that the model should attend to.\n",
    "    + Most of the information needed for generating a reliable prediction is located at the beginning of the sequence.\n",
    "    + There is no restriction on the computational resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Generative modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: VAEs and GANS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggest a method for combining VAEs and GANs. Focus on the different components of the model and how to train them jointly (the objectives). Which drawbacks of these models the combined model may overcome? which not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: Diffusion Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that $q(x_{t-1}|x_t,x_0)$ is tractable and is given by $\\mathcal{N}(x_{t-1};\\tilde{\\mu}(x_t,x_0),\\tilde{\\beta_t}I)$ where the terms for $\\tilde{\\mu}(x_t,x_0)$ and $\\tilde{\\beta_t}$ are given in the last tutorial. Do so by explicitly computing the PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Training Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: Batch Normalization and Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both BatchNorm and Dropout analyze the following:\n",
    "1. How to use them during the training phase (both in forward pass and backward pass)?\n",
    "2. How differently they behave in the inference phase? How to distinguish these operation modes in code?\n",
    "3. Assume you would like to perform multi-GPU training (*) to train your model. What should be done in order for BatchNorm and dropout to work properly? assume that each process holds its own copy of the model and that the processes can share information with each other.\n",
    "\n",
    "(*): In a multi-GPU training each GPU is associated with its own process that holds an independent copy of the model. In each training iteration a (large) batch is split among these processes (GPUs) which compute the gradients of the loss w.r.t the relevant split of the data. Afterwards, the gradients from each process are then shared and averaged so that the GD would take into account the correct gradient and to assure synchornization of the model copies. Note that the proccesses are blocked between training iterations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}